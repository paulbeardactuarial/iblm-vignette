---
title: "IBLM"
author: "Karol Gawlowski and Paul Beard"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
vignette: >
  %\VignetteIndexEntry{Your Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  fig.align = "center"
)
```

## Installation

IBLM can be installed from CRAN or GitHub:

```{r install, eval = FALSE}
# From CRAN
install.packages("IBLM")

# From GitHub
remotes::install_github("IFoA-ADSWP/IBLM")

```

## Introduction

IBLM stands for Interpretable Boosted Linear Models.

An IBLM is essentially a hybrid model consisting of two components:

1.  Generalised Linear Model (GLM) - fitted to the training data

2.  Booster Model[^1] - fitted to the residuals of the training data
    against GLM predictions in step 1.

[^1]: As of v.1.0.0 the IBLM package can only fit a booster model of
    type XGBoost, however we are looking to add other options in the
    future.

The purpose of this Vignette is to show you how to use IBLM to train,
explain and predict using functions from this package.

```{r load-package}

library(IBLM)
library(dplyr)

```

## Process

The overall process for fitting and interpreting an IBLM is as follows:

**Step 1: Fit a GLM**

```         
GLM prediction = β₀ + β₁x₁ + β₂x₂ + ... + βₐxₐ
```

Where β values are your standard regression coefficients.

**Step 2: Train a Booster on GLM's Errors**

Train a booster model (i.e. XGBoost) on the residuals of the actual
response values against the GLM predictions.

**Step 3: Use SHAP to Break Down the Booster**

SHAP decomposition allows the booster's prediction to be apportioned
into contributions from each feature:

```         
Booster prediction = φ₀ + φ₁(x) + φ₂(x) + ... + φₐ(x)
```

Where φⱼ(x) is how much feature j contributed to this specific
prediction.

**Step 4: Convert SHAP Values to Beta Coefficient Corrections**

Transform each SHAP contribution into beta corrections:

```         
αⱼ(x) ≈ φⱼ(x) / xⱼ
```

For instances where xⱼ = 0 the αⱼ(x) is set to 0 and the value is
instead added to an intercept correction, α0.

```         
αⱼ(x) = 0 if xⱼ = 0 
α0​={j∣xj​=0}∑​ϕj​(x)
```

**Step 5: Combine Them**

The final IBLM model can be interpreted as a collection of adjusted
GLMs. Each row of the data will have its own GLM coefficients which are:

1.  The GLM coefficients derived in step 1, which are the same for all
    rows

2.  The beta corrections derived in step 4, which are unique to that
    predictor variable combination.

```         
IBLM = (β₀ + φ₀ + α0) + (β₁ + α₁(x))x₁ + (β₂ + α₂(x))x₂ + ... + (βₐ + αₐ(x))xₐ
```

or

```         
IBLM = β'₀ + β'₁x₁ + β'₂x₂ + ... + β'ₐxₐ
where β'ₐ = (βₐ + αₐ(x)) 
and β'₀ = β₀ + φ₀ + α0
```

This preserves the familiar GLM form while incorporating the booster's
superior predictive power.

## Train

To train an IBLM model we must get our data into an appropriate format.
In this document our demonstrations will be completed using French motor
claims dataset `freMTPL2freq`.

Data for training an IBLM model must be in the form of a list of 3
dataframes. These will be named "train", "validate" and "test". The
function `split_into_train_validate_test()` can conveniently split a
single dataframe into such a structure.

```{r data-prep}

df <- load_freMTPL2freq()

df <- df |> mutate(ClaimNb = round(ClaimNb))

df_list <- df |> split_into_train_validate_test(seed = 1)

```

There is currently only one function available to train an IBLM. This is
`train_iblm_xgb()` which will use xgboost as the booster model. This
performs steps 1 and 2 of the Process.

The output is of class "iblm". Objects of this class contain two
component models "glm_model" and "booster_model". There are also other
items containing information (see Value section of `train_iblm_xgb()`
for more information)

```{r train}

iblm_model <- train_iblm_xgb(
  df_list,
  response_var = "ClaimNb",
  family = "poisson"
)

class(iblm_model)

```

## Explain

Code to explain and interpret an object of class "iblm" are conveniently
wrapped in the `explain_iblm()` function. This performs steps 3, 4 and 5
of the Process. The values derived are all based on the `data` fed in,
which would usually be the test portion of your dataset.

The following line is all that is required:

```{r explain-example}

ex <- explain_iblm(iblm_model, df_list$test)

```

The output object is a list containing the following items:

-   **beta_corrected_scatter** Function to create scatter plots showing
    SHAP corrections vs variable values (see `beta_corrected_scatter()`)

-   **beta_corrected_density** Function to create density plots of SHAP
    corrections for variables (see `beta_corrected_density()`)

-   **bias_density** Function to create density plots of SHAP
    corrections migrated to bias (see `bias_density()`)

-   **overall_correction** Function to show global correction
    distributions (see `overall_correction()`)

-   **shap** Dataframe showing raw SHAP values of data records

-   **beta_corrections** Dataframe showing beta corrections (in
    wide/one-hot format) of data records

-   **data_beta_coeff** Dataframe showing beta coefficients of data
    records

Many of the items output are functions. The functions can then be called
to observe the components of the "iblm" object in different ways.

### Corrected Betas Density

The corrected beta coefficients (β'ₐ) can be observed in a density plot.

When varname is set to be a continuous predictor variables, this
produces a single plot. As shown below - calling the function four times
with four varnames produces four plots.

```{r explain-beta_correct_density-cont}

VehPower <- ex$beta_corrected_density(varname = "VehPower")

VehAge <- ex$beta_corrected_density(varname = "VehAge")

DrivAge <- ex$beta_corrected_density(varname = "DrivAge")

BonusMalus <- ex$beta_corrected_density(varname = "BonusMalus")

```

When varname is set to be a categorical predictor variable, a plot is
produced for each separate level of that categorical variable.

This, however, does not include the reference level. As shown below -
calling the function with "VehBrand", which has 11 levels, produces 10
plots. Because "B1" was used as the reference level it does not have a
beta coefficient within the glm_model. Therefore it is

```{r explain-beta_correct_density-cat}

VehBrand <- ex$beta_corrected_density(varname = "VehBrand", type = "hist")  

VehBrand
```

### Corrected Betas Scatter

The corrected beta values can be observed for

```{r explain-beta_correct_scatter}

ex$beta_corrected_scatter(varname = "DrivAge", color = "VehPower") 

```

### Corrected Biases

As described in step 4 of Process, some shap values cannot be used as
beta corrections (because the predictor value is zero). These values are
instead migrated to the bias. The bias values can be observed with
`bias_density()` .

```{r explain-bias_density}

bias_corrections <- ex$bias_density()

bias_corrections$bias_correction_var

bias_corrections$bias_correction_total

```

### Overall Correction

```{r explain-overall_correction}

ex$overall_correction()

```

## Predict

The package contains a predict method for the class "iblm". This employs
the `predict()` method of both the "glm_model" and "booster_model" items
within the "iblm" class object.

```{r predict-example}

predictions <- predict(iblm_model, df_list$test)

```

Note that because IBLM is essentially a collection of GLMs, and the
corrected beta coefficients are derived by the `explain_iblm()`
function, it is also possible to predict through linear calculation.

```{r predict-alternative}

coeff_multiplier <- 
  df_list$test |>
  select(-all_of("ClaimNb")) |>
  mutate(
    across(
      all_of(iblm_model$predictor_vars$categorical),
      ~1
      )
    ) |>
  mutate(bias = 1, .before = 1)

predictions_alt <- 
  (ex$data_beta_coeff * coeff_multiplier) |>
  rowSums() |> 
  exp() |>
  unname()

# difference in predictions very small between two alternative methods
range(predictions_alt / predictions - 1)

```

## Key Features

### Feature 1

Describe and demonstrate the first major feature.

```{r feature1}
# Demonstration code
```

### Feature 2

Describe and demonstrate the second major feature.

```{r feature2}
# Demonstration code
```

## Advanced Examples

Show more complex use cases that combine multiple functions or
demonstrate advanced functionality.

```{r advanced}
# More complex example
```

## Visualizations

If your package includes plotting functionality, demonstrate it here.

```{r plots}
# Plotting examples
```

## Common Workflows

Walk through typical workflows that users might follow.

```{r workflow}
# Step-by-step workflow example
```

## Tips and Best Practices

Share helpful tips, common pitfalls to avoid, and best practices.

-   Tip 1: Explanation
-   Tip 2: Explanation
-   Tip 3: Explanation

## Troubleshooting

Address common issues users might encounter.

**Problem**: Description of a common problem

**Solution**: How to solve it

```{r troubleshooting, eval = FALSE}
# Example solution code
```

## Summary

Summarize the key points covered in the vignette and suggest next steps
or additional resources.

## Additional Resources

-   Link to package documentation
-   Link to GitHub repository
-   Related packages or resources

## Session Info

```{r session-info}
sessionInfo()
```
