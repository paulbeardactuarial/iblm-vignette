---
title: "IBLM"
author: "Karol Gawlowski and Paul Beard"
date: today
format: 
  html:
    toc: true
    toc-depth: 2
    code-fold: false
    embed-resources: true
---

```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  fig.align = "center"
)
```

```{r create-tabset, include = FALSE}
check_is_rendering <- function() {
  Sys.getenv("QUARTO_PROJECT_ROOT") != ""
}

create_tabset_for_console <- function(x, title = NULL) {
  if (!is.list(x) || is.null(names(x))) {
    stop("Input must be a *named* list.")
  }

  if (!is.null(title)) {
    cat("##", title, "{.tabset}\n\n")
  } else {
    cat("## Output {.tabset}\n\n")
  }

  purrr::iwalk(x, function(value, name) {
    cat("###", name, "\n\n")

    if (is.character(value)) {
      cat(paste(value, collapse = "\n"), "\n\n")
    } else if (is.data.frame(value)) {
      print(gt::gt(value))
    } else {
      print(value)
    }

    cat("\n")
  })
}

create_tabset_for_render <- function(list) {
  chunk <- purrr::imap_chr(list, function(x, y) {
    knitr::knit_child(
      text = c(
        "## `r y`",
        "",
        "```{r}",
        "#| echo: false",
        "x",
        "```",
        "",
        ""
      ), envir = environment(), quiet = TRUE
    )
  })
  cat(chunk, sep = "\n")
}


create_tabset <- function(list, is_rendering = check_is_rendering()) {
  if (is_rendering) {
    create_tabset_for_render(list)
  } else {
    create_tabset_for_console(list)
  }
}
```

## Installation

IBLM can be installed from CRAN or GitHub:

```{r}
#| label: install
#| eval: false
# From CRAN
install.packages("IBLM")

# From GitHub
remotes::install_github("IFoA-ADSWP/IBLM")
```

## Introduction

IBLM stands for "Interpretable Boosted Linear Model".

An IBLM is essentially a hybrid model consisting of two components:

1.  Generalised Linear Model (GLM) - fitted to the training data

2.  Booster Model[^1] - fitted to the residuals of the training data against GLM predictions in step 1.

[^1]: As of v.1.0.0 the IBLM package can only fit a booster model of type XGBoost, however we are looking to add other options in the future.

The purpose of this Vignette is to show you how to use IBLM to train, explain and predict using functions from this package.

```{r}
#| label: load-package
library(IBLM)
library(dplyr)
```

## Process

The overall process for fitting and interpreting an IBLM is as follows:

**Step 1: Fit a GLM**

```         
GLM prediction = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ
```

Where β values are your standard regression coefficients.

**Step 2: Train a Booster on GLM's Errors**

Train a booster model (i.e. XGBoost) on the residuals of the actual response values against the GLM predictions.

**Step 3: Use SHAP to Break Down the Booster**

SHAP decomposition allows the booster's prediction to be apportioned into contributions from each feature:

```         
Booster prediction = φ₀ + φ₁(x) + φ₂(x) + ... + φₙ(x)
```

Where φⱼ(x) is how much feature j contributed to this specific prediction.

**Step 4: Convert SHAP Values to Beta Coefficient Corrections**

Transform each SHAP contribution into beta corrections:

```         
αⱼ(x) ≈ φⱼ(x) / xⱼ
```

For instances where xⱼ = 0 the αⱼ(x) is set to 0 and the value is instead added to an intercept correction, α0.

```         
αⱼ(x) = 0 if xⱼ = 0 
α0​={j∣xj​=0}∑​ϕj​(x)
```

**Step 5: Combine Them**

The final IBLM model can be interpreted as a collection of adjusted GLMs. Each row of the data will have its own GLM coefficients which are:

1.  The GLM coefficients derived in step 1, which are the same for all rows

2.  The beta corrections derived in step 4, which are unique to that predictor variable combination.

```         
IBLM = (β₀ + φ₀ + α0) + (β₁ + α₁(x))x₁ + (β₂ + α₂(x))x₂ + ... + (βₙ + αₙ(x))xₙ
```

or

```         
IBLM = β'₀ + β'₁x₁ + β'₂x₂ + ... + β'ₙxₙ
where β'ⱼ = (βⱼ + αⱼ(x)) 
and β'₀ = β₀ + φ₀ + α0
```

This preserves the familiar GLM form while incorporating the booster's superior predictive power.

## Train

To train an IBLM model we must get our data into an appropriate format. In this document our demonstrations will be completed using French motor claims dataset `freMTPL2freq`.

Data for training an IBLM model must be in the form of a list of 3 dataframes. These will be named "train", "validate" and "test". The function `split_into_train_validate_test()` can conveniently split a single dataframe into such a structure.

```{r}
#| label: data-prep
df <- load_freMTPL2freq()

df <- df |> mutate(ClaimNb = round(ClaimNb))

df_list <- df |> split_into_train_validate_test(seed = 1)

```

There is currently only one function available to train an IBLM. This is `train_iblm_xgb()` which will use xgboost as the booster model. This performs steps 1 and 2 of the Process.

The output is of class "iblm". Objects of this class contain two component models "glm_model" and "booster_model". There are also other items containing information (see Value section of `train_iblm_xgb()` for more information)

```{r}
#| label: train
iblm_model <- train_iblm_xgb(
  df_list,
  response_var = "ClaimNb",
  family = "poisson"
)

class(iblm_model)
```

## Explain

Code to explain and interpret an object of class "iblm" are conveniently wrapped in the `explain_iblm()` function. This performs steps 3, 4 and 5 of the Process. The values derived are all based on the `data` fed in, which would usually be the test portion of your dataset.

The following line is all that is required:

```{r}
#| label: explain-example
ex <- explain_iblm(iblm_model, df_list$test)
```

The output object is a list containing the following items:

-   **beta_corrected_scatter** Function to create scatter plots showing SHAP corrections vs variable values (see `beta_corrected_scatter()`)

-   **beta_corrected_density** Function to create density plots of SHAP corrections for variables (see `beta_corrected_density()`)

-   **bias_density** Function to create density plots of SHAP corrections migrated to bias (see `bias_density()`)

-   **overall_correction** Function to show global correction distributions (see `overall_correction()`)

-   **shap** Dataframe showing raw SHAP values of data records

-   **beta_corrections** Dataframe showing beta corrections (in wide/one-hot format) of data records

-   **data_beta_coeff** Dataframe showing beta coefficients of data records

Many of the items output are functions. The functions can then be called to observe the components of the "iblm" object in different ways.

### Corrected Betas Density

The corrected beta coefficients (β'ⱼ) can be observed in a density plot. This plotting function allows the user to see corrected beta coefficient values for a particular variable.

The density plot also shows the standard error for the original beta coefficient, fitted in the GLM model component. This can be useful to understanding the significance of the range in corrected beta coefficients.

#### Numerical Variables

For numerical variables, calling the function creates a single plot. Below we show examples with different numerical variables from our freMTPL2freq dataset.

::: panel-tabset
##### VehPower

```{r}
#| label: explain-beta_correct_density-VehPower
ex$beta_corrected_density(varname = "VehPower")
```

##### VehAge

```{r}
#| label: explain-beta_correct_density-VehAge
ex$beta_corrected_density(varname = "VehAge")
```

##### DrivAge

```{r}
#| label: explain-beta_correct_density-DrivAge
ex$beta_corrected_density(varname = "DrivAge")
```

##### BonusMalus

```{r}
#| label: explain-beta_correct_density-BonusMalus
ex$beta_corrected_density(varname = "BonusMalus")
```
:::

#### Categorical Variables

For categorical variables, calling the function creates a list of plots. A separate plot is produced for each level of that categorical variable. Note this does not include the reference level. This is demonstrated below with "VehBrand" which has 11 levels and produces 10 plots. Because "B1" was used as the reference level it does not have a beta coefficient within the GLM model component. Instead, those values are migrated to the bias (see below).

::: panel-tabset
```{r}
#| label: beta_correct_density-cat
#| echo: false  
#| results: asis

VehBrand <- ex$beta_corrected_density(varname = "VehBrand", type = "hist")

VehBrand |> create_tabset()
```
:::

### Corrected Betas Scatter

The corrected beta coefficients (β'ⱼ) can be observed in a scatter plot (or boxplot). This plotting function allows the user to see corrected beta coefficient values for a particular variable **and the relationship to that particlar variable value**.

#### Numerical Variables

When varname is set to a numerical variable, a scatter plot is produced. The example below shows the relationship of corrected beta coefficient values against driver age. Note that the original beta coefficient fitted to the GLM component is shown by a dashed black line (and stated near the top of the plot in orange). We can see that corrected beta coefficients can be materially different. There is also a smoothed trend line fitted that shows the overall pattern of correction.

Note the color argument can also be set to try and observe interactions with a second variable. 

```{r}
#| label: explain-beta_correct_scatter
ex$beta_corrected_scatter(varname = "DrivAge", color = "VehPower")
```

### Corrected Biases

As described in step 4 of Process, some shap values cannot be translated to beta corrections. These values are instead migrated to the bias. There are two situations where this can occur:

1.  Numerical variable where the value was zero for that data point.
2.  Categorical variable where the value was the reference level for that data point.

In the `bias_correction_var` plot we visualise all the individual times this occured in our test dataset. For categorical variables Area, Region, VehBrand and VehGas the total counts in the repsective facets of the histogram will equal the total occurences of the reference level for that variable. For numerical variable VehAge the total count in that facet will equal the total occurences of zero for VehAge in the dataset. Other numerical variables are dropped from the plot as they had no instances of zero value (for example DrivAge)

The `bias_correction_total` plot is the cumulative sum of these components across each data point. Note any data point with no bias migration (i.e. conditions 1 and 2 do not occur) will have the standard bias adjustment and is not counted in the plot. The standard bias value, along with standard error around this, can be observed as the straight blue line and dashed orange lines either side.

The bias values can be observed with `bias_density()`.

::: panel-tabset
```{r}
#| label: explain-bias_density
bias_corrections <- ex$bias_density()

bias_corrections |> create_tabset()
```
:::

### Overall Correction

The distribution of overall corrections across your test data can be observed. If the link function is log then the correction is a multiplier (as is the case below). If the link function is identity, then the overall correction is an addition. By default the x scale is transformed by the link function, but this can be switched off.

::: panel-tabset
#### Link Transformed

```{r}
#| label: explain-overall_correction-log
ex$overall_correction()
```

#### Not transformed

```{r}
#| label: explain-overall_correction-identity
ex$overall_correction(transform_x_scale_by_link = FALSE)
```
:::

## Predict

The package contains a predict method for the class "iblm". This employs the `predict()` method of both the "glm_model" and "booster_model" items within the "iblm" class object.

```{r}
#| label: predict-example
predictions <- predict(iblm_model, df_list$test)
```

Note that because IBLM is essentially a collection of GLMs, and the corrected beta coefficients are derived by the `explain_iblm()` function, it is also possible to predict through linear calculation.

```{r}
#| label: predict-alternative
coeff_multiplier <- 
  df_list$test |>
  select(-all_of("ClaimNb")) |>
  mutate(
    across(
      all_of(iblm_model$predictor_vars$categorical),
      ~1
      )
    ) |>
  mutate(bias = 1, .before = 1)

predictions_alt <- 
  (ex$data_beta_coeff * coeff_multiplier) |>
  rowSums() |> 
  exp() |>
  unname()

# difference in predictions very small between two alternative methods
range(predictions_alt / predictions - 1)
```

## Key Features

### Feature 1

Describe and demonstrate the first major feature.

```{r}
#| label: feature1
# Demonstration code
```

### Feature 2

Describe and demonstrate the second major feature.

```{r}
#| label: feature2
# Demonstration code
```

## Advanced Examples

Show more complex use cases that combine multiple functions or demonstrate advanced functionality.

```{r}
#| label: advanced
# More complex example
```

## Visualizations

If your package includes plotting functionality, demonstrate it here.

```{r}
#| label: plots
# Plotting examples
```

## Common Workflows

Walk through typical workflows that users might follow.

```{r}
#| label: workflow
# Step-by-step workflow example
```

## Tips and Best Practices

Share helpful tips, common pitfalls to avoid, and best practices.

-   Tip 1: Explanation
-   Tip 2: Explanation
-   Tip 3: Explanation

## Troubleshooting

Address common issues users might encounter.

**Problem**: Description of a common problem

**Solution**: How to solve it

```{r}
#| label: troubleshooting
#| eval: false
# Example solution code
```

## Summary

Summarize the key points covered in the vignette and suggest next steps or additional resources.

## Additional Resources

-   Link to package documentation
-   Link to GitHub repository
-   Related packages or resources

## Session Info

```{r}
#| label: session-info
sessionInfo()
```
